{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/code/marvin/venv/lib/python3.10/site-packages/hdmf/spec/namespace.py:535: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.3.0 because version 1.8.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n",
      "/home/dima/code/marvin/venv/lib/python3.10/site-packages/hdmf/spec/namespace.py:535: UserWarning: Ignoring cached namespace 'core' version 2.2.5 because version 2.7.0 is already loaded.\n",
      "  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset from 20 trials has 20 samples\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from hand_to_neuro_SingleSessionSingleTrialDataset import SingleSessionSingleTrialDataset\n",
    "import numpy as np\n",
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "import os\n",
    "\n",
    "dataset_path = \"000070\"\n",
    "nwb_file_path = os.path.join(\n",
    "    dataset_path, \"sub-Jenkins\", \"sub-Jenkins_ses-20090916_behavior+ecephys.nwb\")\n",
    "io = NWBHDF5IO(nwb_file_path, 'r')\n",
    "nwb_file = io.read()\n",
    "hand_data = nwb_file.processing['behavior'].data_interfaces['Position']['Hand'].data[:]\n",
    "hand_timestamps = nwb_file.processing['behavior'].data_interfaces['Position']['Hand'].timestamps[:]\n",
    "trial_data = nwb_file.intervals['trials']\n",
    "\n",
    "unit_spike_times = [nwb_file.units[unit_id]['spike_times'].iloc[0][:]\n",
    "                    for unit_id in range(len(nwb_file.units))]\n",
    "n_neurons = len(unit_spike_times)\n",
    "n_future_vel_bins = 20\n",
    "\n",
    "trials_start_from = int(2000 * 0.9)\n",
    "n_trials = int(2000 * 0.01)\n",
    "datasets = [SingleSessionSingleTrialDataset(\n",
    "    trial_data, hand_data, hand_timestamps, unit_spike_times, trial_id, bin_size=0.02, n_future_vel_bins=n_future_vel_bins) for trial_id in range(trials_start_from, trials_start_from + n_trials)]\n",
    "dataset = torch.utils.data.ConcatDataset(datasets)\n",
    "print(f\"Dataset from {n_trials} trials has {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (input_projection): Linear(in_features=232, out_features=512, bias=True)\n",
       "  (pos_encoder): PositionalEncoding()\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_projection): Linear(in_features=512, out_features=1728, bias=True)\n",
       "  (unflatten): Unflatten(dim=2, unflattened_size=(192, 9))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hand_to_neuro_models import TransformerModel\n",
    "from hand_to_neuro_dataloaders import get_max_trial_length\n",
    "\n",
    "n_fr_bins = 9\n",
    "d_model = 512\n",
    "latent_dim = None\n",
    "model_type = \"transformer\"  # transformer, lstm\n",
    "\n",
    "\n",
    "n_trials = 200\n",
    "n_epochs = 200\n",
    "lr = 0.0005\n",
    "weight_decay = 0.0\n",
    "\n",
    "\n",
    "prefix = f\"{model_type}_dm{d_model}\"\n",
    "if latent_dim is not None:\n",
    "    prefix += f\"_ld{latent_dim}\"\n",
    "prefix += f\"_lr{lr}_wd{weight_decay}\"\n",
    "os.makedirs('model_data', exist_ok=True)\n",
    "n_future_vel_bins = 20\n",
    "n_fr_bins = 9\n",
    "bin_size = 0.02\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "max_trial_length = 206#get_max_trial_length(dataset, bin_size, min_max_trial_length_seconds=4)\n",
    "\n",
    "\n",
    "input_size = (n_neurons) + 2 * n_future_vel_bins\n",
    "hidden_size = d_model\n",
    "model = TransformerModel(input_size, hidden_size,\n",
    "                         n_neurons, n_fr_bins, max_trial_length).to(device)\n",
    "checkpoint = torch.load(f'{prefix}_epoch{n_epochs}.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m---> 10\u001b[0m     features, labels \u001b[38;5;241m=\u001b[39m dataset[i]\n\u001b[1;32m     11\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(features)\n\u001b[1;32m     12\u001b[0m     y\u001b[38;5;241m.\u001b[39mappend(labels)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert dataset to PyTorch tensors and move to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "future_vels = []\n",
    "spikes = []\n",
    "spikes_future = []\n",
    "for i in range(len(dataset)):\n",
    "    future_vel, spike, spike_future = dataset[i]\n",
    "    future_vels.append(future_vel)\n",
    "    spikes.append(spike) \n",
    "    spikes_future.append(spike_future)\n",
    "future_vels = torch.stack(future_vels).to(device)\n",
    "spikes = torch.stack(spikes).to(device)\n",
    "spikes_future = torch.stack(spikes_future).to(device)\n",
    "print(\"future_vels.shape\", future_vels.shape, \"spikes.shape\", spikes.shape, \"spikes_future.shape\", spikes_future.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total checkpoint size: 52.52 MB\n",
      "\n",
      "Breakdown by component:\n",
      "model_state_dict: 52.50 MB (100.0%)\n",
      "train_losses: 0.00 MB (0.0%)\n",
      "val_losses: 0.00 MB (0.0%)\n",
      "test_accs: 0.00 MB (0.0%)\n",
      "epoch: 0.00 MB (0.0%)\n",
      "train_loss: 0.00 MB (0.0%)\n",
      "val_loss: 0.00 MB (0.0%)\n",
      "test_acc: 0.00 MB (0.0%)\n",
      "optimizer_state_dict: 0.00 MB (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Print size of each key in the checkpoint and analyze what's taking up space\n",
    "import sys\n",
    "checkpoint = torch.load(f'{prefix}_epoch{n_epochs}.pt', map_location=device)\n",
    "\n",
    "total_size = 0\n",
    "sizes = {}\n",
    "\n",
    "# Calculate size of each component\n",
    "for key, value in checkpoint.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        size_bytes = value.element_size() * value.nelement()\n",
    "        sizes[key] = size_bytes\n",
    "    elif isinstance(value, dict):\n",
    "        total_bytes = 0\n",
    "        for k, v in value.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                total_bytes += v.element_size() * v.nelement()\n",
    "        sizes[key] = total_bytes\n",
    "    elif isinstance(value, list):\n",
    "        size_bytes = sum(sys.getsizeof(item) for item in value)\n",
    "        sizes[key] = size_bytes\n",
    "    else:\n",
    "        sizes[key] = sys.getsizeof(value)\n",
    "    total_size += sizes[key]\n",
    "\n",
    "# Print sizes sorted by largest first\n",
    "print(f\"Total checkpoint size: {total_size / (1024 * 1024):.2f} MB\\n\")\n",
    "print(\"Breakdown by component:\")\n",
    "for key, size in sorted(sizes.items(), key=lambda x: x[1], reverse=True):\n",
    "    pct = (size / total_size) * 100\n",
    "    print(f\"{key}: {size / (1024 * 1024):.2f} MB ({pct:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or if you only need the model weights\n",
    "torch.save(model.state_dict(), f'{prefix}_epoch{n_epochs}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
